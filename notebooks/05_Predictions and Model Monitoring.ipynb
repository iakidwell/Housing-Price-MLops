{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7970877-d584-44ce-a554-a921251bc2e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook 5: Inferencing with Deployed Model\n",
    "\n",
    "### In this notebook, we deploy the model previously logged to MLflow and make some predictions to demonstrate that it works. We also transform some of the data in the test set to practice model monitoring in Databricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cba4e75d-ffaa-47ac-908a-227415e87fdd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded for inference!\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load registered model\n",
    "# ----------------------------\n",
    "model_name = \"rf_ames_model\"\n",
    "model_version = 1 \n",
    "\n",
    "# Construct the MLflow model URI\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "# Load the model\n",
    "loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "print(\"Model loaded for inference!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f5195ba-5571-4cbc-b291-d1b1c15bca57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded X_test from: /Users/iankidwell/Documents/Housing-Price-MLops/data/X_test.csv\n",
      "X_test shape: (586, 55), y_test shape: (586,)\n",
      "   Order        PID  MS SubClass  Lot Frontage  Lot Area  Overall Qual  \\\n",
      "0   1358  903427090           70          68.0      5100             8   \n",
      "1   2368  527450460          160          21.0      1890             6   \n",
      "2   2823  908128100           60          62.0      7162             7   \n",
      "3   2127  907135180           20          60.0      8070             4   \n",
      "4   1545  910200080           30          50.0      7000             6   \n",
      "\n",
      "   Overall Cond  Year Built  Year Remod/Add  Mas Vnr Area  ...  Open Porch SF  \\\n",
      "0             7        1925            1996           0.0  ...             63   \n",
      "1             7        1972            1972         380.0  ...              0   \n",
      "2             5        2003            2004         190.0  ...             57   \n",
      "3             5        1994            1995           0.0  ...              0   \n",
      "4             8        1926            1998           0.0  ...              0   \n",
      "\n",
      "   Enclosed Porch  3Ssn Porch  Screen Porch  Pool Area  Pool QC  Misc Val  \\\n",
      "0               0           0             0          0        0         0   \n",
      "1               0           0             0          0        0         0   \n",
      "2               0           0             0          0        0         0   \n",
      "3               0           0             0          0        0         0   \n",
      "4             116           0             0          0        0         0   \n",
      "\n",
      "   Mo Sold  Yr Sold  SalePrice  \n",
      "0        6     2008     161000  \n",
      "1        7     2006     116000  \n",
      "2        5     2006     196500  \n",
      "3        8     2007     123600  \n",
      "4        7     2008     126000  \n",
      "\n",
      "[5 rows x 55 columns]\n",
      "0    11.989166\n",
      "1    11.661354\n",
      "2    12.188423\n",
      "3    11.724814\n",
      "4    11.744045\n",
      "Name: SalePrice_log, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 2. Load test data for evaluation\n",
    "# ----------------------------\n",
    "\n",
    "# --- FIX: Read from the local data folder ---\n",
    "# Use relative paths so it works for anyone cloning the repo\n",
    "X_test_path = \"../data/X_test.csv\"\n",
    "y_test_path = \"../data/y_test.csv\"\n",
    "\n",
    "# Load test features and target\n",
    "X_test = pd.read_csv(X_test_path)\n",
    "y_test = pd.read_csv(y_test_path).squeeze()  # squeeze to convert to Series\n",
    "\n",
    "# Verification\n",
    "print(f\"Loaded X_test from: {os.path.abspath(X_test_path)}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "print(X_test.head())\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c63f1ab8-c996-4004-a5c0-29e981d6bb59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE on deployed model: 3305.82\n",
      "Example 1 predicted SalePrice: $161847.65\n",
      "Example 2 predicted SalePrice: $116013.15\n",
      "Example 3 predicted SalePrice: $196344.90\n",
      "Example 4 predicted SalePrice: $124188.16\n",
      "Example 5 predicted SalePrice: $125872.61\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Make predictions on test set\n",
    "# ----------------------------\n",
    "preds_log = loaded_model.predict(X_test)\n",
    "\n",
    "# Invert the log transform to get SalePrice\n",
    "preds = np.expm1(preds_log)  # converts log(SalePrice+1) back to SalePrice\n",
    "y_test_actual = np.expm1(y_test)  # convert actual log values back\n",
    "\n",
    "# Calculate RMSE manually\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, preds))\n",
    "print(f\"Test RMSE on deployed model: {rmse:.2f}\")\n",
    "\n",
    "# Display the first 5 predictions\n",
    "for i, price in enumerate(preds[:5], 1):\n",
    "    print(f\"Example {i} predicted SalePrice: ${price:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ff1bb99-7e4d-4e72-a613-7bacb575f009",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged test evaluation to MLflow run a1efa3f0a87e4e3aa2fe8adb77eb6a8f\n",
      "Saved predictions to: /Users/iankidwell/Documents/Housing-Price-MLops/data/test_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- FIX 1: Portable Experiment Name ---\n",
    "# Replace the hardcoded path with a simple name.\n",
    "# mlflow.set_experiment() automatically creates it if it doesn't exist.\n",
    "experiment_name = \"ames_housing_test_eval\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Start a run in this experiment\n",
    "with mlflow.start_run(run_name=\"deployed_model_test_eval\") as run:\n",
    "    \n",
    "    # Log metric (Ensure 'rmse' variable exists from previous cells)\n",
    "    mlflow.log_metric(\"test_rmse\", rmse)\n",
    "\n",
    "    # --- FIX 2: Save to Data Folder ---\n",
    "    eval_df = pd.DataFrame({\n",
    "        \"y_true\": y_test,  # Changed 'y_test_actual' to 'y_test' to match previous steps\n",
    "        \"y_pred\": preds    # Ensure your predictions are named 'preds'\n",
    "    })\n",
    "    \n",
    "    # Save to ../data/ instead of current folder\n",
    "    eval_csv_path = \"../data/test_predictions.csv\"\n",
    "    eval_df.to_csv(eval_csv_path, index=False)\n",
    "    \n",
    "    # Log the file as an artifact\n",
    "    mlflow.log_artifact(eval_csv_path)\n",
    "\n",
    "    print(f\"Logged test evaluation to MLflow run {run.info.run_id}\")\n",
    "    print(f\"Saved predictions to: {os.path.abspath(eval_csv_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13de3ae6-6fe0-4abe-8875-a35642c6ea47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Feature Changes\n",
    "\n",
    "## This is done to test out the modeling monitoring dashboard in Databricks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc0497af-bf37-4802-9e96-2f0c4e9e77e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features in the dataset:\n",
      "1. MS SubClass\n",
      "2. Lot Frontage\n",
      "3. Lot Area\n",
      "4. Overall Qual\n",
      "5. Overall Cond\n",
      "6. Year Built\n",
      "7. Year Remod/Add\n",
      "8. Mas Vnr Area\n",
      "9. Exter Qual\n",
      "10. Exter Cond\n",
      "11. Bsmt Qual\n",
      "12. Bsmt Cond\n",
      "13. Bsmt Exposure\n",
      "14. BsmtFin Type 1\n",
      "15. BsmtFin SF 1\n",
      "16. BsmtFin Type 2\n",
      "17. BsmtFin SF 2\n",
      "18. Bsmt Unf SF\n",
      "19. Total Bsmt SF\n",
      "20. Heating QC\n",
      "21. 1st Flr SF\n",
      "22. 2nd Flr SF\n",
      "23. Low Qual Fin SF\n",
      "24. Gr Liv Area\n",
      "25. Bsmt Full Bath\n",
      "26. Bsmt Half Bath\n",
      "27. Full Bath\n",
      "28. Half Bath\n",
      "29. Bedroom AbvGr\n",
      "30. Kitchen AbvGr\n",
      "31. Kitchen Qual\n",
      "32. TotRms AbvGrd\n",
      "33. Functional\n",
      "34. Fireplaces\n",
      "35. Fireplace Qu\n",
      "36. Garage Yr Blt\n",
      "37. Garage Finish\n",
      "38. Garage Cars\n",
      "39. Garage Area\n",
      "40. Garage Qual\n",
      "41. Garage Cond\n",
      "42. Paved Drive\n",
      "43. Wood Deck SF\n",
      "44. Open Porch SF\n",
      "45. Enclosed Porch\n",
      "46. 3Ssn Porch\n",
      "47. Screen Porch\n",
      "48. Pool Area\n",
      "49. Pool QC\n",
      "50. Misc Val\n",
      "51. Mo Sold\n",
      "52. Yr Sold\n",
      "53. SalePrice\n"
     ]
    }
   ],
   "source": [
    "# List all features in X_test\n",
    "print(\"Features in the dataset:\")\n",
    "for i, col in enumerate(X_test.columns, 1):\n",
    "    print(f\"{i}. {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "674a3a88-b9a1-4624-9824-f90bedac125d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE on mutated test data: 3369.46\n",
      "Logged RMSE to MLflow run a426a1daf6c04e159aae3b835b57d28c\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import mlflow\n",
    "\n",
    "# Make a copy of X_test so we don't overwrite original test data\n",
    "X_test_mutated = X_test.copy()\n",
    "\n",
    "# Specify the features to modify\n",
    "feature_1 = \"Lot Area\"\n",
    "feature_2 = \"Fireplaces\"\n",
    "\n",
    "# Mutate the features: random perturbation\n",
    "np.random.seed(42)  # for reproducibility\n",
    "X_test_mutated[feature_1] = X_test_mutated[feature_1] + np.random.normal(0, 1, size=X_test_mutated.shape[0])\n",
    "X_test_mutated[feature_2] = X_test_mutated[feature_2] + np.random.normal(0, 1, size=X_test_mutated.shape[0])\n",
    "\n",
    "# Predict with the deployed model\n",
    "mutated_preds_log = loaded_model.predict(X_test_mutated)\n",
    "mutated_preds = np.expm1(mutated_preds_log)  # invert log-transform\n",
    "\n",
    "# Evaluate RMSE on mutated data (manual square root)\n",
    "# Note: Ensure 'y_test' is defined from your previous cells\n",
    "y_test_actual = np.expm1(y_test)\n",
    "mutated_rmse = mean_squared_error(y_test_actual, mutated_preds) ** 0.5\n",
    "print(f\"Test RMSE on mutated test data: {mutated_rmse:.2f}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Log evaluation with MLflow\n",
    "# ----------------------------\n",
    "\n",
    "# --- FIX: Portable Experiment Name ---\n",
    "# Use the same experiment name we set in the previous cell\n",
    "experiment_name = \"ames_housing_test_eval\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=\"mutated_test_eval\") as run:\n",
    "    mlflow.log_metric(\"mutated_test_rmse\", mutated_rmse)\n",
    "    print(f\"Logged RMSE to MLflow run {run.info.run_id}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_Predictions and Model Monitoring",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
