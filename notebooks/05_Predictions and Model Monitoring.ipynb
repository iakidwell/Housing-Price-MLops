{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7970877-d584-44ce-a554-a921251bc2e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook 5: Inferencing with Deployed Model\n",
    "\n",
    "### In this notebook, we deploy the model previously logged to MLflow and make some predictions to demonstrate that it works. We also transform some of the data in the test set to practice model monitoring in Databricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cadc38af-39ac-45bd-8598-d2479413a05b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd3dc0d4-fa73-42c4-bf46-68a72f9a4c36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define path \n",
    "input_path = \"../data/ames_preprocessed_numeric_unscaled.csv\"\n",
    "\n",
    "# Check if file exists to avoid path errors\n",
    "if not os.path.exists(input_path):\n",
    "    print(f\"‚ö†Ô∏è Warning: File not found at {input_path}\")\n",
    "    print(\"Trying absolute path or checking current directory...\")\n",
    "    # Fallback: check if the file is in the same folder\n",
    "    input_path = \"ames_preprocessed_numeric_unscaled.csv\"\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Define target column\n",
    "target = \"SalePrice_log\"\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Split into train/test sets (MUST use same random_state=42 as training!)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Data loaded! X_test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69f9b23d-1c1c-4ccf-bafc-4b208e8770d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This is a model monitoring function, in lieu of proper model monitoring functionality in the databricks free edition\n",
    "\n",
    "def monitor_model_performance(model_alias, X_data, y_true_log, data_name=\"Test Data\", rmse_threshold=40000):\n",
    "    \"\"\"\n",
    "    Simulates a Model Monitoring Job.\n",
    "    Converts LOG predictions back to DOLLARS for a realistic report.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üì° STARTING MONITORING JOB: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"üéØ Target Model Alias: @{model_alias}\")\n",
    "    print(f\"üìä Data Source: {data_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # 1. Load the \"Production\" Model\n",
    "    model_uri = f\"models:/{model_name}@{model_alias}\"\n",
    "    production_model = mlflow.sklearn.load_model(model_uri)\n",
    "    \n",
    "    # 2. Run Inference\n",
    "    print(f\"   ü§ñ Running inference on {len(X_data)} samples...\")\n",
    "    log_predictions = production_model.predict(X_data)\n",
    "    \n",
    "    # 3. CONVERT TO DOLLARS (Fixing the unit mismatch)\n",
    "    # np.expm1 reverses the log(x+1) transformation\n",
    "    pred_dollars = np.expm1(log_predictions)\n",
    "    actual_dollars = np.expm1(y_true_log)\n",
    "    \n",
    "    # 4. Calculate RMSE in Real Dollars\n",
    "    rmse_dollars = np.sqrt(((pred_dollars - actual_dollars) ** 2).mean())\n",
    "    \n",
    "    # 5. Generate Monitoring Report\n",
    "    print(f\"\\nüìã --- MONITORING REPORT ---\")\n",
    "    print(f\"   ‚úÖ Metric Evaluated: RMSE (Dollars)\")\n",
    "    print(f\"   üìâ Current Performance: ${rmse_dollars:,.2f}\")\n",
    "    print(f\"   üìè Threshold Limit:     ${rmse_threshold:,.2f}\")\n",
    "    \n",
    "    # 6. Status Check\n",
    "    if rmse_dollars < rmse_threshold:\n",
    "        print(f\"\\n   üü¢ STATUS: HEALTHY. Model is performing within expected limits.\")\n",
    "    else:\n",
    "        print(f\"\\n   üî¥ STATUS: ALERT! Model performance has degraded.\")\n",
    "        print(f\"      Action: Trigger retraining or investigate data drift.\")\n",
    "        \n",
    "    print(f\"{'='*60}\\n\")\n",
    "    return rmse_dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a7f8ff8-09a5-4622-8bb9-c5324f2f1526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. Construct the Model URI\n",
    "# IMPORTANT: Use the EXACT name you see in the \"Models\" UI (e.g., \"main.default.rf_ames_model\")\n",
    "model_name = \"rf_ames_model\" \n",
    "model_uri = f\"models:/{model_name}@prod\"\n",
    "\n",
    "print(f\"Attempting to load model from: {model_uri}\")\n",
    "\n",
    "# 2. Load the model\n",
    "# We use sklearn.load_model because that's how we saved it\n",
    "production_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "print(\"‚úÖ Model loaded successfully!\")\n",
    "\n",
    "# 3. (Optional) Inspect the model to be sure\n",
    "print(f\"Model type: {type(production_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f825d84-12b2-4d9c-9dd2-a3580fb6b305",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Validate Deployed Model on Normal Test Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c877662-893d-4b1c-852c-e76bd642f93e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- INFERENCE DEMO ---\n",
    "print(\"üöÄ Loading Deployed Model (@prod)...\")\n",
    "model_uri = f\"models:/{model_name}@prod\"\n",
    "production_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "# 1. Select 5 random houses from the test set\n",
    "sample_data = X_test.sample(5, random_state=42)\n",
    "sample_indices = sample_data.index\n",
    "\n",
    "# 2. Get the Actual Prices (and convert from Log back to Dollars)\n",
    "actual_log = y_test.loc[sample_indices]\n",
    "actual_prices = np.expm1(actual_log)\n",
    "\n",
    "# 3. Generate Predictions (and convert from Log back to Dollars)\n",
    "print(f\"üîÆ Predicting prices for {len(sample_data)} houses...\")\n",
    "pred_log = production_model.predict(sample_data)\n",
    "pred_prices = np.expm1(pred_log)\n",
    "\n",
    "# 4. Create a Comparison Table\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual Price': actual_prices,\n",
    "    'Predicted Price': pred_prices,\n",
    "    'Difference ($)': pred_prices - actual_prices,\n",
    "    'Error %': np.abs((pred_prices - actual_prices) / actual_prices) * 100\n",
    "})\n",
    "\n",
    "# Formatting for nice display\n",
    "pd.options.display.float_format = '${:,.2f}'.format\n",
    "print(\"\\n‚ú® INFERENCE RESULTS (Sample):\")\n",
    "display(results_df)\n",
    "\n",
    "# Reset formatting (optional)\n",
    "pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47596187-6d48-4967-9813-e2c58b889b4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set up model monitoring by calling function\n",
    "monitor_model_performance(\n",
    "    model_alias=\"prod\", \n",
    "    X_data=X_test, \n",
    "    y_true_log=y_test, \n",
    "    data_name=\"Standard Holdout Test Set\",\n",
    "    rmse_threshold=40000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13de3ae6-6fe0-4abe-8875-a35642c6ea47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Feature Changes\n",
    "\n",
    "## This is done to test out the modeling monitoring dashboard in Databricks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc0497af-bf37-4802-9e96-2f0c4e9e77e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- STEP 8: Simulate Data Drift (The \"Broken\" Pipeline) ---\n",
    "print(\"‚ö†Ô∏è INJECTING DATA DRIFT...\")\n",
    "X_test_drifted = X_test.copy()\n",
    "\n",
    "# SCENARIO 1: Data Entry Error (Garage Area becomes 5x larger)\n",
    "# Using 'Garage Area' (with space) based on your feature list\n",
    "X_test_drifted['Garage Area'] = X_test_drifted['Garage Area'] * 5 \n",
    "\n",
    "# SCENARIO 2: Sensor Failure (Living Area reads as 0)\n",
    "# Using 'Gr Liv Area' (with space) based on your feature list\n",
    "X_test_drifted['Gr Liv Area'] = 0\n",
    "\n",
    "print(\"Data corruption complete. Sending to production model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fcefe75-d270-4252-b650-a8dec4c39a02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- STEP 8: Simulate CATASTROPHIC Data Drift ---\n",
    "print(\"‚ö†Ô∏è INJECTING CATASTROPHIC DATA DRIFT...\")\n",
    "X_test_drifted = X_test.copy()\n",
    "\n",
    "# GO NUCLEAR: Multiply ALL data by 100\n",
    "# This simulates a currency/unit conversion error affecting the whole dataset\n",
    "X_test_drifted = X_test_drifted * 100\n",
    "\n",
    "print(\"Data is now completely broken. Sending to production model...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0a39e80-7e4d-42bb-bc1d-2beaa2ffde7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Verify data drift through model monitoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc907d96-f7ef-4cd3-bff6-9d9d853acd21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- STEP 9: Verify Monitoring Catch (The \"Red\" Status) ---\n",
    "monitor_model_performance(\n",
    "    model_alias=\"prod\", \n",
    "    X_data=X_test_drifted, \n",
    "    y_true_log=y_test, \n",
    "    data_name=\"üî• COMPLETELY BROKEN DATA\",\n",
    "    rmse_threshold=40000 \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_Predictions and Model Monitoring",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
