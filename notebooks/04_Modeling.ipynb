{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93074190-0dbb-4693-91f8-bf9146dc48b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook 4: Model Deployment\n",
    "\n",
    "### AutoML from the previous notebook gave us the insight that a random forest regressor with the parameters inserted below is a strong modeling choice. We will go with that and deploy this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9905a5f2-4d1f-47e0-95f2-de0a4824aa3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "\n",
    "# 1. Get your username (email) programmatically\n",
    "username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "\n",
    "# 2. Define a path in your Workspace (NOT in the Repo)\n",
    "experiment_name = \"ames_housing_mlops\"\n",
    "experiment_path = f\"/Users/{username}/{experiment_name}\"\n",
    "\n",
    "# 3. Set the experiment\n",
    "mlflow.set_experiment(experiment_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4142fc2f-23d4-4006-9a9a-dc8d6602c7a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The '..' goes up one level from 'notebooks/', then into 'data/'\n",
    "input_path = \"../data/ames_preprocessed_numeric_unscaled.csv\"\n",
    "\n",
    "# Load the CSV\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Verification\n",
    "print(f\"Successfully loaded data from: {os.path.abspath(input_path)}\")\n",
    "print(df.head())\n",
    "\n",
    "# Define target column\n",
    "target = \"SalePrice_log\"\n",
    "\n",
    "# Split features and target\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Quick check\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c3f06707-593e-4a30-a0c7-31d7dba265e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Use relative paths so it works on GitHub clones\n",
    "test_features_path = \"../data/X_test.csv\"\n",
    "test_target_path = \"../data/y_test.csv\"\n",
    "\n",
    "# Save features and target separately\n",
    "X_test.to_csv(test_features_path, index=False)\n",
    "y_test.to_csv(test_target_path, index=False)\n",
    "\n",
    "# Verification: Print the absolute path to confirm they landed in the right spot\n",
    "print(f\"Test features saved to: {os.path.abspath(test_features_path)}\")\n",
    "print(f\"Test target saved to:   {os.path.abspath(test_target_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22c4742c-886b-48da-a38e-759c9157d2cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Initialize the client\n",
    "client = MlflowClient()\n",
    "\n",
    "# Example using AutoML-best parameters\n",
    "rf = RandomForestRegressor(\n",
    "    max_features=0.9269,\n",
    "    max_leaf_nodes=357,\n",
    "    n_estimators=8,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Infer model signature based on training data and predictions\n",
    "train_preds = rf.predict(X_train)\n",
    "signature = infer_signature(X_train, train_preds)\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(run_name=\"rf_ames_model\") as run:\n",
    "    # Log model with signature\n",
    "    mlflow.sklearn.log_model(rf, \"rf_model\", signature=signature)\n",
    "    \n",
    "    # Log metrics\n",
    "    test_preds = rf.predict(X_test)\n",
    "    rmse = ((test_preds - y_test)**2).mean()**0.5\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    print(f\"Run ID: {run.info.run_id}, Test RMSE: {rmse}\")\n",
    "\n",
    "    # Register the model\n",
    "    model_name = \"rf_ames_model\"\n",
    "    model_uri = f\"runs:/{run.info.run_id}/rf_model\"\n",
    "    registered_model = mlflow.register_model(model_uri, model_name)\n",
    "\n",
    "    print(f\"Model registered: {registered_model.name}, version: {registered_model.version}\")\n",
    "\n",
    "print(f\"Deploying version {registered_model.version} to 'prod'...\")\n",
    "\n",
    "client.set_registered_model_alias(\n",
    "    name=model_name,\n",
    "    alias=\"prod\",\n",
    "    version=registered_model.version\n",
    ")\n",
    "\n",
    "print(f\"âœ… SUCCESS: Model '{model_name}' (Version {registered_model.version}) is now deployed as '@prod'.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Modeling",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
